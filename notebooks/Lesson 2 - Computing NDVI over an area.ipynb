{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing NDVI over farmland\n",
    "\n",
    "### Download your Landsat scene\n",
    "\n",
    "Use the instructions at the beginning of `Lesson 1` to download another scene. This time, we're looking for some farm land. Take a guess at an area that is highly covered by farmable land, and download the __Red__ and __Infrared__ bands.\n",
    "\n",
    "#### Note: Record the date of the Landsat scene. We're going to use the date the Landsat scene was taken later, so write it down!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in the last lesson, we'll load up the raster data from our bands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "landsat_scene_name = \"LC08_L1TP_042035_20171022_20171107_01_T1\"\n",
    "\n",
    "red_path = os.path.join(\"/home/hadoop/data/\", \n",
    "                        \"{}_B4.TIF\".format(landsat_scene_name))\n",
    "ir_path = os.path.join(\"/home/hadoop/data/\", \n",
    "                       \"{}_B5.TIF\".format(landsat_scene_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "with rasterio.open(red_path) as ds:\n",
    "    red_data = ds.read()\n",
    "    \n",
    "with rasterio.open(ir_path) as ds:\n",
    "    ir_data = ds.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use some of `numpy`'s computational capabilites to do some band math. We'll be computing the [Normalized difference vegetation index](https://en.wikipedia.org/wiki/Normalized_difference_vegetation_index), which computes the ratio of the difference and the sum of the Red and Near Infrared bands of Landsat to create a value that has proven to be an efficient indicator of vegetation health. The formula for NDVI is:\n",
    "\n",
    "![NDVI](img/ndvi.png)\n",
    "\n",
    "The range for this function is `-1.0` to `1.0`. The greater the number, the greater the indication of healthy vegetation.\n",
    "\n",
    "To encode this in `numpy` operations, first we will change our values to floating point so that the result of the operation is also a floating point value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "r = red_data[0].astype(float)\n",
    "ir = ir_data[0].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we utilize numpy's overriding of the division, subtraction and addition operators to write code that looks a whole lot like the original formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = (ir - r) / (ir + r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice a warning that occurs, which happens when the division hits a `0` value for the `ir` and `r` data. This happens because `0` is used as a `nodata` value for Landsat. To get around this, we can use `numpy` syntax to set every 0 to `nan` (Not A Number):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = red_data[0].astype(float)\n",
    "r[r == 0.0] = np.nan\n",
    "ir = ir_data[0].astype(float)\n",
    "ir[ir == 0.0] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the division does not throw this warning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndvi = (ir - r) / (ir + r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be computing NDVI a number of times, so let's refactor the above code into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_ndvi(r, ir):\n",
    "    rf = r.astype(float)\n",
    "    rf[r == 0] = np.nan\n",
    "    irf = ir.astype(float)\n",
    "    irf[ir == 0] = np.nan\n",
    "    return (irf - rf) / (irf + rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndvi = compute_ndvi(red_data[0], ir_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Statistics of the NDVI\n",
    "\n",
    "Here we inspect statistics of the NDVI values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flattened = np.ravel(ndvi[~np.isnan(ndvi)])\n",
    "\n",
    "print(\"MEAN: {}\".format(np.mean(flattened)))\n",
    "print(\"MEDIAN: {}\".format(np.median(flattened)))\n",
    "print(\"MIN: {}\".format(np.min(flattened)))\n",
    "print(\"MAX: {}\".format(np.max(flattened)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(flattened, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rendering of the histogram should give you an idea of the normal range of NDVI values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clipping out a subset of fields\n",
    "\n",
    "We're now going to use [geojson.io](http://geojson.io) to find a subset of the data to work with, that contains fields for us to analyze.\n",
    "\n",
    "Let's get the bounds of the image, as well as the CRS from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with rasterio.open(red_path) as ds:\n",
    "    bounds = ds.bounds\n",
    "    crs = ds.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create a `shapely` polygon out of the bounds, and use the `mapping` method to turn it into a GeoJSON `dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "\n",
    "bounds_poly = Polygon([(bounds.left, bounds.bottom),\n",
    "                       (bounds.left, bounds.top),\n",
    "                       (bounds.right, bounds.top),\n",
    "                       (bounds.right, bounds.bottom),\n",
    "                       (bounds.left, bounds.bottom)])\n",
    "\n",
    "bounds_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import mapping\n",
    "\n",
    "m = mapping(bounds_poly)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice the coordinates don't look anything like the lat/long coordinates from the county in Lesson 1. Again, we have to mind our projections. These coordinates are in the image's CRS, so let's reproject them to lat/long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reproject to LatLng\n",
    "import pyproj\n",
    "from musa import reproject_geom # From Lesson 1\n",
    "\n",
    "image_proj = pyproj.Proj(crs)\n",
    "lat_lng_proj = pyproj.Proj(init=\"epsg:4326\")\n",
    "ll_bounds_poly = reproject_geom(bounds_poly, image_proj, lat_lng_proj)\n",
    "ll_bounds_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice I imported the `reproject_geom` method from a `musa`. This is a module that lives in the workshop repository, in which I've put some methods that either we have already gone over or aren't valuable to the lesson at hand.\n",
    "\n",
    "Now, we can print out the GeoJSON and load it up in geojson.io:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dump to GeoJSON\n",
    "import json\n",
    "\n",
    "geojson = json.dumps(mapping(ll_bounds_poly), indent=4)\n",
    "print(geojson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the GeoJSON and paste it into [geojson.io](http://geojson.io). It should look something like this:\n",
    "\n",
    "![geojson.io](img/geojson-io-1.png)\n",
    "\n",
    "Zoom into a part of the land covered by the polygon that seems likely to be covered by farmland. It's useful to hit the \"Satellite\" basemap toggle on the bottom left. Once you've zoomed to your area, use the trash icon to delete the bounds polygon:\n",
    "\n",
    "![geojson.io](img/geojson-io-2.png)\n",
    "\n",
    "Now, use the polygon icon to draw a polygon around some fields. Try to make the area big enough that it covers a lot of farmland, but not so big that we might as well not be subsetting: \n",
    "\n",
    "![geojson.io](img/geojson-io-3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy out all the text in the GeoJSON editor and paste it to replace `<YOUR TEXT HERE>` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in GeoJSON\n",
    "\n",
    "crop_area_geojson = \"\"\"\n",
    "<YOUR TEXT HERE>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can grab the geometry from the FeatureCollection of the GeoJSON, reproject to the Landsat scene's CRS, and use it as a mask to  crop our NDVI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import shape\n",
    "\n",
    "crop_area_json = json.loads(crop_area_geojson)['features'][0]['geometry']\n",
    "crop_area_ll = shape(crop_area_json)\n",
    "crop_area_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crop_area = reproject_geom(crop_area_ll, lat_lng_proj, image_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rasterio.mask import mask\n",
    "\n",
    "with rasterio.open(red_path) as ds:\n",
    "    (cropped_red_data, cropped_transform) = mask(ds, [mapping(crop_area)], crop=True)\n",
    "    crs = ds.crs\n",
    "    out_meta = ds.meta.copy()\n",
    "\n",
    "# Save a GeoTiff\n",
    "with rasterio.open(ir_path) as ds:\n",
    "    (cropped_ir_data, _) = mask(ds, [mapping(crop_area)], crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cropped_ndvi = compute_ndvi(cropped_red_data[0], cropped_ir_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we targeted farm land, one might think the stats for NDVI will shift towards `1.0`. However, because many fields might either not be in growing season or have already been harvested, you might find the numbers don't change that much or may even skew downward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cropped_flattened = np.ravel(cropped_ndvi[~np.isnan(cropped_ndvi)])\n",
    "print(\"MEAN: {}\".format(np.mean(cropped_flattened)))\n",
    "print(\"MEDIAN: {}\".format(np.median(cropped_flattened)))\n",
    "print(\"MIN: {}\".format(np.min(cropped_flattened)))\n",
    "print(\"MAX: {}\".format(np.max(cropped_flattened)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(cropped_flattened, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Viewing NDVI\n",
    "\n",
    "Let's take a look at the NDVI. NDVI is often viewed with a color palette that shows more intense green where there is healthy vegitation. Here we define a matplotlib color map based on blues and greens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Divergent Blue to Beige to Green colormap\n",
    "cmap = LinearSegmentedColormap.from_list(\n",
    "  'ndvi', ['blue', 'beige', 'green'], 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then show the image rendered with this color map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from musa import show_image # From Lesson 1\n",
    "\n",
    "show_image(cropped_ndvi, cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already you might be able to see distinct fields that are either harvested (having low NDVI values) or currently growing (having high NDVI values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Writing a GeoTiff\n",
    "\n",
    "With rasterio, you can write out data to a GeoTIFF. Here we write out our NDVI data, so that we can for example view it in [QGIS](https://qgis.org/en/site/) or process it further with [GDAL](http://www.gdal.org/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_image = np.expand_dims(ndvi, axis=0)\n",
    "\n",
    "out_meta.update({\"driver\": \"GTiff\",\n",
    "                 \"dtype\": \"float64\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": cropped_transform})\n",
    "\n",
    "with rasterio.open(\"/home/hadoop/data/croptest.tif\", \"w\", **out_meta) as dest:\n",
    "    dest.write(out_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing with GeoPySpark and GeoNotebook\n",
    "\n",
    "Another option to view is to use [GeoPySpark](https://geopyspark.readthedocs.io/en/latest/) put the data on this map __â†’__\n",
    "\n",
    "We haven't utilized this map and GeoPySpark and [GeoNotebook](https://github.com/OpenGeoscience/geonotebook) for a couple of reasons, mainly because these topics are out of scope for the workshop. However, let's use some functionality I put into the `musa` code to render our NDVI onto the map.\n",
    "\n",
    "First we take the bounds of image, center the map on it, and call the `map_ndvi` method to render it to the map. This might take a few minutes. For a peak under the hood, check out the python code in the `musa` directory of this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rasterio.transform import array_bounds\n",
    "from rasterio.coords import BoundingBox\n",
    "\n",
    "b = array_bounds(cropped_red_data.shape[1], cropped_red_data.shape[2], cropped_transform)\n",
    "bounds = BoundingBox(b[0], b[1], b[2], b[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from musa import map_ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "center = crop_area_ll.centroid\n",
    "M.set_center(center.x, center.y, z = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your data isn't small or your machine is underpowered, this next step can take a bit. If it's taking a while, or you are interested, go to http://locahost:4040 and check on the spark job. Each tile is served out of an Apache Spark RDD from an in-memory tile server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove any previously placed on layers\n",
    "for l in M.layers:\n",
    "    M.remove_layer(l)\n",
    "\n",
    "map_ndvi(M, cropped_ndvi, bounds, crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Finding the NDVI values of a single field\n",
    "\n",
    "We'll use the GeoNotebook functionality for drawing a polygon on the  map, and use it to single out an individual field in our data.\n",
    "\n",
    "Click the draw polygon button in the toolbar of this notebook. It looks like this:\n",
    "\n",
    "![Draw Polygon](img/geonotebook-draw.png)\n",
    "\n",
    "Then draw a polygon around a field that looks particularly healthy.\n",
    "\n",
    "Now we can grab the polygon using the GeoNotebook annotation layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aoi = M.layers.annotation.polygons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rasterio has a `features.geom_mask` function that will create a mask of raster data based on a geometry you pass in. We can use this to mask out the part of the image that is not covered by our polygon, and then show a histogram of values that represent our field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rasterio import features\n",
    "\n",
    "r_aoi = reproject_geom(aoi, lat_lng_proj, image_proj)\n",
    "geom_mask = features.geometry_mask(\n",
    "        [r_aoi],\n",
    "        out_shape=cropped_ndvi.shape,\n",
    "        transform=cropped_transform\n",
    "    )\n",
    "masked = np.ma.array(data=cropped_ndvi, mask=geom_mask)\n",
    "np.mean(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(np.ravel(cropped_ndvi[~np.isnan(cropped_ndvi)]), bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoNotebook + GeoPySpark",
   "language": "python",
   "name": "geonotebook3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
